{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45a8503f84e84c178e84ee4fa7a926e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/224 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oyku_\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\oyku_\\.cache\\huggingface\\hub\\models--microsoft--trocr-large-printed. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ae7c235ec1540ee8d13c1955ab02b4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.12k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d21df5340fc7430c8188884804f921ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f04488f3870453a87d418639f18898d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b4426c9351d472ba9814c8091dc2958",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/772 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dc10ff236a6434aa6e5f71b90e6b84d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/4.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b780f558cd740dd92c74c24e1445351",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.43G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VisionEncoderDecoderModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-large-printed and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59aa3f4ae48743e0955c4d68bf16f876",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "processor = TrOCRProcessor.from_pretrained('microsoft/trocr-large-printed')\n",
    "model = VisionEncoderDecoderModel.from_pretrained('microsoft/trocr-large-printed')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image_2.png...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oyku_\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\generation\\utils.py:1220: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "The channel dimension is ambiguous. Got image shape (3, 603, 3). Assuming channels are the first dimension.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing recipe_img (1).jpg...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The channel dimension is ambiguous. Got image shape (3, 338, 3). Assuming channels are the first dimension.\n",
      "The channel dimension is ambiguous. Got image shape (3, 205, 3). Assuming channels are the first dimension.\n",
      "The channel dimension is ambiguous. Got image shape (3, 164, 3). Assuming channels are the first dimension.\n",
      "The channel dimension is ambiguous. Got image shape (3, 377, 3). Assuming channels are the first dimension.\n",
      "The channel dimension is ambiguous. Got image shape (3, 111, 3). Assuming channels are the first dimension.\n",
      "The channel dimension is ambiguous. Got image shape (3, 204, 3). Assuming channels are the first dimension.\n",
      "The channel dimension is ambiguous. Got image shape (3, 123, 3). Assuming channels are the first dimension.\n",
      "The channel dimension is ambiguous. Got image shape (3, 312, 3). Assuming channels are the first dimension.\n",
      "The channel dimension is ambiguous. Got image shape (3, 304, 3). Assuming channels are the first dimension.\n",
      "The channel dimension is ambiguous. Got image shape (3, 166, 3). Assuming channels are the first dimension.\n",
      "The channel dimension is ambiguous. Got image shape (3, 142, 3). Assuming channels are the first dimension.\n",
      "The channel dimension is ambiguous. Got image shape (3, 152, 3). Assuming channels are the first dimension.\n",
      "The channel dimension is ambiguous. Got image shape (3, 104, 3). Assuming channels are the first dimension.\n",
      "The channel dimension is ambiguous. Got image shape (3, 110, 3). Assuming channels are the first dimension.\n",
      "The channel dimension is ambiguous. Got image shape (3, 114, 3). Assuming channels are the first dimension.\n",
      "The channel dimension is ambiguous. Got image shape (3, 613, 3). Assuming channels are the first dimension.\n",
      "The channel dimension is ambiguous. Got image shape (3, 119, 3). Assuming channels are the first dimension.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing recipe_img (2).jpg...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The channel dimension is ambiguous. Got image shape (3, 113, 3). Assuming channels are the first dimension.\n",
      "The channel dimension is ambiguous. Got image shape (3, 178, 3). Assuming channels are the first dimension.\n",
      "The channel dimension is ambiguous. Got image shape (3, 138, 3). Assuming channels are the first dimension.\n",
      "The channel dimension is ambiguous. Got image shape (3, 171, 3). Assuming channels are the first dimension.\n",
      "The channel dimension is ambiguous. Got image shape (3, 196, 3). Assuming channels are the first dimension.\n",
      "The channel dimension is ambiguous. Got image shape (3, 220, 3). Assuming channels are the first dimension.\n",
      "The channel dimension is ambiguous. Got image shape (3, 178, 3). Assuming channels are the first dimension.\n",
      "The channel dimension is ambiguous. Got image shape (3, 118, 3). Assuming channels are the first dimension.\n",
      "The channel dimension is ambiguous. Got image shape (3, 118, 3). Assuming channels are the first dimension.\n",
      "The channel dimension is ambiguous. Got image shape (3, 109, 3). Assuming channels are the first dimension.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing recipe_img (3).jpg...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The channel dimension is ambiguous. Got image shape (3, 111, 3). Assuming channels are the first dimension.\n",
      "The channel dimension is ambiguous. Got image shape (3, 274, 3). Assuming channels are the first dimension.\n",
      "The channel dimension is ambiguous. Got image shape (3, 273, 3). Assuming channels are the first dimension.\n",
      "The channel dimension is ambiguous. Got image shape (3, 236, 3). Assuming channels are the first dimension.\n",
      "The channel dimension is ambiguous. Got image shape (3, 295, 3). Assuming channels are the first dimension.\n",
      "The channel dimension is ambiguous. Got image shape (3, 156, 3). Assuming channels are the first dimension.\n",
      "The channel dimension is ambiguous. Got image shape (3, 154, 3). Assuming channels are the first dimension.\n",
      "The channel dimension is ambiguous. Got image shape (3, 256, 3). Assuming channels are the first dimension.\n",
      "The channel dimension is ambiguous. Got image shape (3, 111, 3). Assuming channels are the first dimension.\n",
      "The channel dimension is ambiguous. Got image shape (3, 112, 3). Assuming channels are the first dimension.\n",
      "The channel dimension is ambiguous. Got image shape (3, 109, 3). Assuming channels are the first dimension.\n",
      "The channel dimension is ambiguous. Got image shape (3, 119, 3). Assuming channels are the first dimension.\n",
      "The channel dimension is ambiguous. Got image shape (3, 133, 3). Assuming channels are the first dimension.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing recipe_img (4).jpg...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The channel dimension is ambiguous. Got image shape (3, 123, 3). Assuming channels are the first dimension.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing recipe_img (5).jpg...\n",
      "Processing recipe_img (6).jpg...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The channel dimension is ambiguous. Got image shape (3, 134, 3). Assuming channels are the first dimension.\n",
      "The channel dimension is ambiguous. Got image shape (3, 125, 3). Assuming channels are the first dimension.\n",
      "The channel dimension is ambiguous. Got image shape (3, 104, 3). Assuming channels are the first dimension.\n",
      "The channel dimension is ambiguous. Got image shape (3, 133, 3). Assuming channels are the first dimension.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing recipe_img_test.jpg...\n",
      "Processing recipe_img_test_2.jpg...\n",
      "Processing test.jpg...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The channel dimension is ambiguous. Got image shape (3, 235, 3). Assuming channels are the first dimension.\n",
      "The channel dimension is ambiguous. Got image shape (3, 251, 3). Assuming channels are the first dimension.\n",
      "The channel dimension is ambiguous. Got image shape (3, 228, 3). Assuming channels are the first dimension.\n",
      "The channel dimension is ambiguous. Got image shape (3, 277, 3). Assuming channels are the first dimension.\n",
      "The channel dimension is ambiguous. Got image shape (3, 274, 3). Assuming channels are the first dimension.\n",
      "The channel dimension is ambiguous. Got image shape (3, 118, 3). Assuming channels are the first dimension.\n",
      "The channel dimension is ambiguous. Got image shape (3, 247, 3). Assuming channels are the first dimension.\n",
      "The channel dimension is ambiguous. Got image shape (3, 188, 3). Assuming channels are the first dimension.\n",
      "The channel dimension is ambiguous. Got image shape (3, 114, 3). Assuming channels are the first dimension.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing test_hand.jpg...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The channel dimension is ambiguous. Got image shape (3, 137, 3). Assuming channels are the first dimension.\n",
      "The channel dimension is ambiguous. Got image shape (3, 116, 3). Assuming channels are the first dimension.\n",
      "The channel dimension is ambiguous. Got image shape (3, 152, 3). Assuming channels are the first dimension.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Texts extracted from image_2.png:\n",
      "AMMOVAY\n",
      "MONROE\n",
      "\n",
      "Texts extracted from recipe_img (1).jpg:\n",
      "TOTAL :\n",
      "@WATEROTWHIMSY\n",
      "THE USE ARE BEEME REQUIRED OF CROSS OR REQUIRED\n",
      "ITEM KING TIME INCLUSIVE\n",
      "TOP AND SPREAD\n",
      "THANK YOU ARE REVERSE\n",
      "THANK YOU ARE ARE MORE INCLUSIVE RECEIPT FOR AN OFFER\n",
      "ITEMLINE:\n",
      "SATIN AND RETURN MEAT\n",
      "AVIMHIA IN MISH MADE EINSAVA\n",
      "YOUR CHILLED STREUSEL OUT OF\n",
      "7.SLOWLY ADD YOUR DRY INGREDIENTS TO THE WET IN\n",
      "6. IN A SEPARATE BOWL, MIX ALL THE DRY INGR\n",
      "AND PUMPKIN PUREE TOGETHER.\n",
      "4. IN A LARGE BOWL, MIX OIL, SUGAR,\n",
      "ITEM\n",
      "INNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN\n",
      "REFERENCE EXCHANGE ARE BE MORE REFERENT\n",
      "INNNNNNNNNNNNNNN\n",
      "1.MIX ALL THE STROUSEL INGREDIENTS TOGETHER AND\n",
      "4\n",
      "ITEM\n",
      "GROUND CLOVES\n",
      "TOTAL\n",
      "T-\n",
      "SALES EXCHANGE INCE\n",
      "TSD. CINNAMON\n",
      "1/4 CUP BROWN SUG\n",
      "THANK YOU ARE ARE\n",
      "ITEM\n",
      "1/4 CUN MANLE SUMMARY\n",
      "HHHHHHHHHH\n",
      "3\n",
      "ITEM\n",
      "1/2 CUP POWDERED SUGAR\n",
      "1/2 CUP VEGETABLE OIL\n",
      "PARA YAYA\n",
      "INVIVENTAL\n",
      "ITEM\n",
      "TOTAL:\n",
      "1\n",
      ".................\n",
      "\n",
      "Texts extracted from recipe_img (2).jpg:\n",
      "TOTAL:\n",
      "RECEIVE BY WILLAN CULSING\n",
      "SUBJECT:\n",
      "AMOUNT INCOME FOR\n",
      "3.BAKE AT 170ÂºC FOR 25MIN.\n",
      "L PARTIALLY-BAKED\n",
      "TOTAL RETRILL BELL\n",
      "ITEM\n",
      "SO DON'T WORRY! PRESS PASTRY INSIDE THE MOLD UNTIL\n",
      "YAWAYA 41 JOHORAN MARAN AVANI 1X 20 JAL\n",
      "SALAN MENTUN TRANSACTION RETURN IS\n",
      "TOTAL INCLUSIVE INCLUSIVE INLINE\n",
      "3. ROLL IT OUT BETWEEN 2 OVER PAPERS (THICKNESS AR\n",
      "2, WRAP DOUGH RIGHT WITH FILM PAPER AND CHILL IN THE FR\n",
      "THANK YOU FOR INVERSE FOR THE ORDER OF\n",
      "SALESTAX INCLUSIVE\n",
      "ITEM\n",
      "PUMPKIN\n",
      "\n",
      "Texts extracted from recipe_img (3).jpg:\n",
      "ITEMLINE INCLUSIVE IN NEED\n",
      "ITEMAMOUNT\n",
      "VEGETABLES AND SAUCE FROM THE SLOW COOKER. THEY'RE\n",
      "G. SERVE: KEMORE THE DAY LEAVES AND DISCARD. SER\n",
      "TOTAL: X X X X X X X X X X X X X X X X\n",
      "SANDWICH NAME OF RECEIPT FOR AN OFFER INCLUSIVE FOR AN\n",
      "3. LOOK: LOVER AND COOK ON LOW FOR / 6 HOURS OR ON HIGH\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "AMOUNT OF RECEIPT FOR AN OFFER OF TRANSACTION AND RETURN FOR AN\n",
      "4.ADD HERDS AND VEGETABLES: ADD THE HYME, BAY\n",
      "XXXXXXXXX XXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "SALES EXCHANGES INCLUSIVE INCLUSIONS\n",
      "WWW.SALAWAY.COM/SALPHS/VIVANAW\n",
      "CROCKPOT, ADD THE MINced RATING. POUR IN THE BEST BROTH\n",
      "3. COMBINE EVERYTHING IN THE CROCKPOT: PIACE THE SEASON\n",
      "PLEASE ITEM ISSUANTATIVE FOR US ONLINE WITH US ON/S SAV\n",
      "XXXXX XXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "MEDIUM-HIGH HEAT. SEAF THE SHORT MBS ON ALL SALES\n",
      "2. SEAR THE RIBS (OPTIONAL BUT RECOMMENDED): HE\n",
      "1. SEASON THE SHORT RIBS: GENEROUSLY SEASON THE SH\n",
      "ITEM\n",
      "BARANANAN MINIHOR\n",
      "AMOUNT AND RETURN MEATEN INCOME FOR AN OFFER\n",
      "KENT PERFINAL: 01/1/2018\n",
      "SALES EXCHANGE INCLUSIVE THE\n",
      "SALES EXCHANGES INCLUSIVE IN\n",
      ". 3 LBS BONE-IN BEET SHORT NBS\n",
      "CASHIER WITH RECEIPT FOR WITH WITH WITH WITH WITH WITH WITH WITH WITH WITH\n",
      "\n",
      "Texts extracted from recipe_img (4).jpg:\n",
      "-SROTETN\n",
      "TOTAL\n",
      "Y\n",
      "-\n",
      "-\n",
      "C SDAONETO TO MIXLUTE, COUN WI\n",
      "CHILE STRING FOR 5 MORE MINUTES FOR FLAVORS TO BLEND\n",
      "TOTAL\n",
      "TOTAL\n",
      "SUBJECTED INCLUSIVE INLINE\n",
      "ITEM UT IQU POPPUT HUMM\n",
      "PER\n",
      "E\n",
      "OUTIMP SCAMPI SPAGNETTI (I SERVING)\n",
      "VIVIVY\n",
      "AMPOI\n",
      "\n",
      "Texts extracted from recipe_img (5).jpg:\n",
      "AMOUNT\n",
      "TOTAL\n",
      "AMOUNT\n",
      "TOTAL\n",
      "SUPER\n",
      "ITIT\n",
      "4-4-4-4-4-4-4-4-4-4\n",
      "1\n",
      "V\n",
      "\n",
      "Texts extracted from recipe_img (6).jpg:\n",
      "A WITE PACK BEFORE CUTTING INTO SQUARES.\n",
      "8. COOL AND SERVE. ALLOW THE BROWNIES TO COOL COMPI\n",
      "TOOTHPICK INSERTED INTO THE CENTER COMES OUT WITH A NEW MOIST\n",
      "EYENLY. BAKE IN THE PREMEATED OVER FOR 20-25 MINUTES\n",
      "/. BAKE: POUR THE BATTER INTO THE PREPARED BAKING DAN\n",
      "6. ADD CHOCOLATE CHIPS: FOID IN THE CHOCOLATE CH\n",
      "RA COMAMPL NOT FO\n",
      "THE WET INGREDIENTS, STRING UNTIL JUST COMBINED\n",
      "3. MIX WET AND DRY INGREDIENTS: GRAQUALLY\n",
      "COCOA POWDER, SALT, BAKING POWDER, AND FLOUR.\n",
      "4. COMBINE DTY INGRETENTS: IN A SEPARATE BOW\n",
      "TIME, BEATING WELL ATTER EACH ADDITION. SUR IN THE VANILA\n",
      "GRANULATED SUGAR, MIX UNTIL WELL COMBINED\n",
      "OPONULATED CHOPP\n",
      "3. MIX WET INGREDIENTS: IN A LARGE BOWL\n",
      "UNCE MELTED, REMOVE FROM HEAT AND ALLOW TO COOL S\n",
      "SUBJECT CODE:\n",
      "2. MELT BUTTER: IN A MEDIUM SAUCEPAN OVER LOW HE\n",
      "LINE AN 8X8 INCH BAKING PAN WITH PARCHMENT PAPER.\n",
      "SIT SUMMARY\n",
      "I. PLEASE YOUR OVER: PREMEAT YOUR OVER TO 350 F (1/3\n",
      "509 /18:00\n",
      "INSTRUCTIONS:\n",
      "17 CUN CEMLEWEST CHOCOLATE CHING\n",
      "1\n",
      "CASHIER\n",
      "4 TEASPOON SALT\n",
      "TOTAL RETURNS AND US ON BACK OF RECEIPT FOR AN OFFER\n",
      "TEASDOON VANILA\n",
      "ITEM\n",
      "COCON BANDER\n",
      "1/2 CUP UNSWEETENED\n",
      "2 LARGE EPOS\n",
      "CUP GRANULATED SUGAR\n",
      "1/2 CUP (1 STICK) UNSALTED BUTTER\n",
      "INGREDIENTS:\n",
      "ITEM\n",
      "PLIVIN\n",
      "INCLUDED\n",
      "........\n",
      "\n",
      "Texts extracted from recipe_img_test.jpg:\n",
      "SPULITVM\n",
      "AMPOI\n",
      "\n",
      "Texts extracted from recipe_img_test_2.jpg:\n",
      "OUTIMP SCAMPI SPAGNETTI (I SERVING)\n",
      "GOOD APPL\n",
      "\n",
      "Texts extracted from test.jpg:\n",
      "ITAVAILIATIVE VEGU VIVAN\n",
      "AMPLIMMYASSOMAAN AAM\n",
      "AMOUNT AND RETURN ME INCLUSIVE INCLUSIVE RETURNS AND\n",
      "IT FROM TEMBERATURE WITH BUTTER OR IAM\n",
      "12. ALLOW THE BUNS TO COME AGAIN BETORE SERVING, PLAY\n",
      "14. REMOVE THE BUNS FROM THE OVER AND BRUSH THEM WITH THE GA\n",
      "with WATER IN A SAMALL SAUCEPAN OVER LOW HEAT UNTIL M\n",
      "L& WILL THE BUNS ARE MAKING, PERATE THE GUIZE BY MEAT\n",
      "INVOICE WITH RECEIPT FOR AN OFFER INCLUSIVE OF RECEIP\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "12. MAKE THE BUNS IN THE PROHERATED OVER FOR 20-25 MIN\n",
      "THANK YOU FOR MORE FOR MORE RETURNS ON BACK OF RECEIPT FOR\n",
      "AMOUNT AND CHANGE INCLUSIVE WITHIN THE MARKET OF RECEIPT FOR\n",
      "THE PASTE TO A PAPING DATEA WITH A SHALL FOUND UP (\n",
      "IT. TO MAKE THE CROSS SUPPING, MAXtogether THE HOUR AND WEEK TO\n",
      "9. WHITE THE BUNS ARE RISING, PREMEAT YOUR OVER TO 375%\n",
      "INVOICE FOR RETURN ME WITH\n",
      "AMOUNT AND RETURNS AND EXCHANGES INCLUSIVE INCLUSIVE IN NEED\n",
      "8. COVER THE BUNS WITH A CLEAN KATCHEN TOWER OF PL\n",
      "BALLS OF DOUGH ON A GREASED BAKING SHEET, LEAVING\n",
      "/INVOICE THE DOUGH INTO 12 EQUAL PORTIONS AND SHAPE CASH\n",
      "G. L.MICE THE DOUGH HAS NEED, PUNCH IT DOWN AND KREAD\n",
      "RISE IN A WAYM, DRAIT-FREE PLACE FOR ABOUT 1-1\n",
      "S. PLACE THE DOUGH IN A GREASED BAND, COVER WITH A CHEN\n",
      "XXXXXXXXX XXXXXX XXXXXXXXXXXXXXXXX\n",
      "4. TURN THE DOUGH OUT ONTO A LIGHTLY BLOWERED SULT\n",
      ".S. MAKE A WELL IN THE CENTER OF THE MY IMPORTMENTS, THEN\n",
      "2. IN A SEPARATE BONL, WASK TAGEETHER THE\n",
      "CUP INHACU ULLOW ITEM\n",
      "/4 CUP UNSALTED BUTTER, MELTED\n",
      "TOTAL\n",
      "HHH\n",
      "\n",
      "Texts extracted from test_hand.jpg:\n",
      "APPLE ON DURING\n",
      "WVUAD JU DUMP\n",
      "ITEMLINE INLINE INCLUSIVE\n",
      "TOTAL\n",
      "TOTAL\n",
      "UND DRUG\n",
      "VANILLA AND\n",
      "PLOWIT SUQUE\n",
      "PLY BULTPR.SUDOR\n",
      "TOTAL\n",
      "INSUOA RICE\n",
      "74 CUP BROWN SUQOR | 3/4 CUPS OP FLOUR\n",
      "-WP PANIM JUD\n",
      "ITEM MENTHOL\n",
      "CL CUP CHOCOLATE CHIPS\n",
      "T- -------\n",
      "WWW WWW.\n",
      "-\n",
      "ITTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTT\n",
      "TOTAL\n",
      "TOTAL\n",
      "-\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def process_image(image_path):\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply Gaussian blur\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "    # Perform edge detection\n",
    "    edges = cv2.Canny(blurred, 50, 150, apertureSize=3)\n",
    "\n",
    "    # Find lines in the image\n",
    "    lines = cv2.HoughLinesP(edges, 1, np.pi / 180, threshold=100, minLineLength=100, maxLineGap=10)\n",
    "\n",
    "    # Create a mask for the lines\n",
    "    line_mask = np.zeros_like(image)\n",
    "\n",
    "    # Draw detected lines on the mask\n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            x1, y1, x2, y2 = line[0]\n",
    "            cv2.line(line_mask, (x1, y1), (x2, y2), (255, 255, 255), 2)\n",
    "\n",
    "    # Find contours of the lines to extract text regions\n",
    "    contours, _ = cv2.findContours(cv2.cvtColor(line_mask, cv2.COLOR_BGR2GRAY), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Process each contour\n",
    "    extracted_texts = []\n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        # Extract the line of text\n",
    "        line_image = image[y:y+h, x:x+w]\n",
    "\n",
    "        # Convert to PIL image for processing with TrOCR\n",
    "        pil_image = Image.fromarray(cv2.cvtColor(line_image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        # Process the line with TrOCR\n",
    "        pixel_values = processor(images=pil_image, return_tensors=\"pt\").pixel_values\n",
    "        generated_ids = model.generate(pixel_values)\n",
    "        generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "\n",
    "        # Store the extracted text\n",
    "        extracted_texts.append(generated_text)\n",
    "\n",
    "    return extracted_texts\n",
    "\n",
    "def process_images_in_directory(directory):\n",
    "    all_extracted_texts = {}\n",
    "\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "            image_path = os.path.join(directory, filename)\n",
    "            print(f'Processing {filename}...')\n",
    "            extracted_texts = process_image(image_path)\n",
    "            all_extracted_texts[filename] = extracted_texts\n",
    "\n",
    "    return all_extracted_texts\n",
    "\n",
    "# Example usage\n",
    "directory = 'C:\\\\Users\\\\oyku_\\\\Desktop\\\\image_pro\\\\recipe_pics\\\\recipes' \n",
    "all_texts = process_images_in_directory(directory)\n",
    "\n",
    "# Print all extracted texts\n",
    "for image_name, texts in all_texts.items():\n",
    "    print(f\"\\nTexts extracted from {image_name}:\")\n",
    "    for text in texts:\n",
    "        print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
